{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push/Pull to AWS\n",
    "* Training DF files\n",
    "* then push other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#set path directory\n",
    "\n",
    "#load access key\n",
    "#HOME = os.path.expanduser('~')\n",
    "HOME = os.getcwd()\n",
    "HOME = os.chdir('..')\n",
    "HOME = os.getcwd()\n",
    "# HOME = os.getcwd()\n",
    "KEYPATH = \"utils/AWSaccessKeys.csv\"\n",
    "ACCESS = pd.read_csv(f\"{HOME}/{KEYPATH}\")\n",
    "\n",
    "#start session\n",
    "SESSION = boto3.Session(\n",
    "    aws_access_key_id=ACCESS['Access key ID'][0],\n",
    "    aws_secret_access_key=ACCESS['Secret access key'][0],\n",
    ")\n",
    "S3 = SESSION.resource('s3')\n",
    "#AWS BUCKET information\n",
    "BUCKET_NAME = 'national-snow-model'\n",
    "BUCKET = S3.Bucket(BUCKET_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training DF regional files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload nearest-snotel dictionaries\n",
    "regionlist = ['SouthernRockies', 'Southwest', 'Northwest']\n",
    "output_res = 300\n",
    "\n",
    "for region in regionlist:\n",
    "    print(region)\n",
    "    head_folder = f\"SWEMLv2.0/data/TrainingDFs/{region}/300M_Resolution\"\n",
    "    head_folder_dir = f\"{HOME}/{head_folder}\"\n",
    "\n",
    "    #Get files only\n",
    "    files = [f for f in listdir(head_folder_dir) if isfile(join(head_folder_dir, f))]\n",
    "    # for file in tqdm_notebook(files):\n",
    "    #     S3.meta.client.upload_file(Filename= f\"{head_folder_dir}{file}\", Bucket=BUCKET_NAME, Key=f\"{head_folder}{file}\")\n",
    "\n",
    "    #get list of directories to download\n",
    "    dirs = [ f.path for f in os.scandir(head_folder_dir) if f.is_dir() ]\n",
    "    for dir in dirs:\n",
    "        print(f\"Folder name: {dir.split('300M_Resolution/')[-1]}\")\n",
    "        awsfolderpath = f\"SWEMLv2.0{dir.split('SWEMLv2.0')[-1]}\"\n",
    "        headfolderpath = f\"{HOME}/{awsfolderpath}\"\n",
    "        files = [f for f in listdir(headfolderpath) if isfile(join(headfolderpath, f))]\n",
    "        # for file in tqdm_notebook(files):\n",
    "        #      S3.meta.client.upload_file(Filename= f\"{headfolderpath}/{file}\", Bucket=BUCKET_NAME, Key=f\"{awsfolderpath}/{file}\")\n",
    "        #     # print(f\"{headfolderpath}/{file}\")\n",
    "\n",
    "        # # #Get subfolders\n",
    "        subdirs = [ f.path for f in os.scandir(headfolderpath) if f.is_dir() ]\n",
    "        for dir in subdirs:\n",
    "            print(f\"Folder name: {dir.split('300M_Resolution/')[-1]}\")\n",
    "            awsfolderpath2 = f\"SWEMLv2.0{dir.split('SWEMLv2.0')[-1]}\"\n",
    "            headfolderpath2 = f\"{HOME}/{awsfolderpath2}\"\n",
    "            files = [f for f in listdir(headfolderpath2) if isfile(join(headfolderpath2, f))]\n",
    "            for file in tqdm_notebook(files):\n",
    "                S3.meta.client.upload_file(Filename= f\"{headfolderpath2}/{file}\", Bucket=BUCKET_NAME, Key=f\"{awsfolderpath2}/{file}\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload nearest-snotel dictionaries\n",
    "regionlist = ['Northwest','SouthernRockies', 'Southwest' ]\n",
    "output_res = 500\n",
    "\n",
    "#Get data\n",
    "for region in regionlist:\n",
    "    print(region)\n",
    "    path = f\"SWEMLv2.0/data/TrainingDFs/{region}/{output_res}M_Resolution\"\n",
    "\n",
    "    #Make directory if it does not exist\n",
    "    if not os.path.exists(f\"{HOME}/{path}\"):\n",
    "        print(\"Path not present, making\")\n",
    "        os.makedirs(f\"{HOME}/{path}\", exist_ok=True)\n",
    "    \n",
    "    #Identify the potential files to download\n",
    "    files = [objects.key for objects in BUCKET.objects.filter(Prefix=path)]\n",
    "    #print(files)\n",
    "    \n",
    "    for file in tqdm_notebook(files):\n",
    "        #Make directory if it does not exist\n",
    "        if not os.path.exists(f\"{HOME}/{path}\"):\n",
    "            print(\"Path not present, making\")\n",
    "        os.makedirs( os.path.dirname(f\"{HOME}/{file}\"), exist_ok=True)\n",
    "       \n",
    "        #check to see if the file is there\n",
    "        if os.path.exists(f\"{HOME}/{file}\") == False:\n",
    "            print('Downloading file')\n",
    "            S3.Bucket(BUCKET_NAME).download_file(file, f\"{HOME}/{file}\")\n",
    "\n",
    "        else:\n",
    "            print('File already present...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.dirname(f\"{HOME}/Test/{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload nearest-snotel dictionaries\n",
    "regionlist = ['Northwest', 'Northwest'] #'SouthernRockies', 'Southwest' ]\n",
    "output_res = 500\n",
    "\n",
    "#Get data\n",
    "for region in regionlist:\n",
    "    print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just want to list all prefixes to see file structure \n",
    "client = SESSION.client('s3')\n",
    "\n",
    "response = client.list_objects_v2(\n",
    "    Bucket=BUCKET_NAME,\n",
    "    Delimiter='/'\n",
    ")\n",
    "\n",
    "prefixes = response.get('CommonPrefixes', [])\n",
    "for prefix in prefixes:\n",
    "    print(prefix['Prefix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for obj in BUCKET.objects.filter(Prefix='SWEMLv2.0/Predictions'):\n",
    "    # print(obj.key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push model predictions \n",
    "\n",
    "WY_list = [2013,2024]\n",
    "# WY_list = [2014]\n",
    "thresh = 10\n",
    "res = 1000\n",
    "df = 'NLDASDaymet_Vegetation_Sturm_Seasonality_VIIRSGeoObsDFs'\n",
    "folder = f'{HOME}/Predictions/{df}/{res}M_Resolution/{thresh}_fSCA_Thresh'\n",
    "\n",
    "for year in WY_list:\n",
    "    filepath = f'{folder}/{year}/GeoTiffs'\n",
    "    files = [file for file in os.listdir(filepath) if file.endswith('tif')]\n",
    "    for file in files:\n",
    "        localpath = f'{filepath}/{file}'\n",
    "        if os.path.isfile(localpath) == True:\n",
    "            # print(localpath)\n",
    "            key = f'SWEMLv2.0/Predictions/{res}M_Resolution/{thresh}_fSCA_Thresh/{year}/{file}'\n",
    "            BUCKET.upload_file(\n",
    "                Filename=localpath,\n",
    "                Key=key\n",
    "                )\n",
    "\n",
    "            # print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SWEML_310",
   "language": "python",
   "name": "sweml_310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
