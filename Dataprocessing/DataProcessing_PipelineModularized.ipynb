{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9685d109",
   "metadata": {},
   "source": [
    "# Data Processing script for the NSM/SWEML v2.0\n",
    "This .ipynb script uses python module for retrieving NASA ASO observations, locating nearest SNOTEL sites, connecting SNOTEL obs with ASO obs, and add geospatial features to the ML training/testing/hindcast dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13469889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ASOget import ASODownload, ASODataProcessing\n",
    "\n",
    "# Inputs for fetching ASO data for a region\n",
    "short_name = 'ASO_50M_SWE'\n",
    "version = '1'\n",
    "time_start = '2013-04-02T00:00:00Z'\n",
    "time_end = '2019-07-19T23:59:59Z'\n",
    "region = 'S_Sierras'\n",
    "folder_name = f\"SWE_Data/{region}\"\n",
    "output_res = 100 #desired spatial resoultion in meters (m)\n",
    "directory = \"SWE_Data\"\n",
    "\n",
    "#Get ASO data\n",
    "data_tool = ASODownload(short_name, version)\n",
    "selected_region = data_tool.select_region(region)  # Call select_region on the instance, S Sierras is #2. There may be a need to modify this in order to cover CONUS, create region folders...\n",
    "\n",
    "print(f\"Fetching file URLs in progress for {selected_region} from {time_start} to {time_end}\")\n",
    "url_list = data_tool.cmr_search(time_start, time_end, data_tool.bounding_box)\n",
    "data_tool.cmr_download(directory, region)\n",
    "\n",
    "print('Converting .tif to csv')\n",
    "data_processor = ASODataProcessing()\n",
    "data_processor.convert_tiff_to_csv(folder_name, output_res, region) #Takes ~3 mins, can it be multithreaded?\n",
    "\n",
    "#Applying polygon geometries, please be patient, this step can take a few minutes...Converting to GeoDataFrame\n",
    "input_folder = f\"ASO/{output_res}M_SWE_csv/{region}\"\n",
    "metadata_file = f\"grid_cells_meta.csv\"\n",
    "output_folder = f\"Processed_SWE/{region}\"\n",
    "data_processor.process_folder(input_folder, metadata_file, output_folder) #Takes ~20 minutes. Can this be multithreaded?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a329ea64",
   "metadata": {},
   "source": [
    "# Code for generating ML dataframe using nearest in situ monitoring sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aacde450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all Geospatial prediction/observation files and concatenating into one dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:26<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing nan ASO sites and saving geodataframe to TrainingDFs S_Sierras folder.\n",
      "Identifying unique sites to create geophysical information dataframe\n",
      "converting to geodataframe\n",
      "Loading SNOTEL metadata and processing snotel geometry\n",
      "Processing snotel geometry\n",
      "Calculating haversine distance from each cell to in situ OBS, and saving cell-obs relationships in dictionary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1361698it [13:52, 1635.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest SNOTEL in S_Sierras for each cell id in a pkl file\n",
      "Loading geospatial data for S_Sierras\n",
      "Converting to geodataframe\n",
      "Calculating dataframe bounding box\n",
      "Retrieving Copernicus 90m DEM tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 7584.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 tiles in the region\n",
      "Interpolating Grid Cell Spatial Features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 135.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job complete for getting geospatial metadata, processing dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:55,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving S_Sierras dataframe in /home/rjohnson18/SWEMLv2.0/data/TrainingDFs/S_Sierras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import GeoDF\n",
    "\n",
    "# GeoDF used to create a dataframe for ML model development. Its function is to connect in situ observations to gridded locations\n",
    "region = 'S_Sierras' #Should be done in above code block\n",
    "output_res = 100\n",
    "\n",
    "#load snotel meta location data, use haversive function\n",
    "GeoDF.fetch_snotel_sites_for_cellids(region) # Using known up to date sites, can this be threaded?\n",
    "\n",
    "# Get geophysical attributes for each site, need to see how to add output resolution\n",
    "gdf = GeoDF.GeoSpatial(region)\n",
    "gdf = gdf.head(100)\n",
    "#use geodataframe with lat/long meta of all sites to determine slope, aspect, and elevation\n",
    "metadf = GeoDF.extract_terrain_data_threaded(gdf, region)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "573a5df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting site observations with nearest monitoring network obs\n",
      "Loading observations from 2013-2019\n",
      "Loading goeospatial meta data for grids in S_Sierras\n",
      "Loading 100M resolution grids for S_Sierras region\n",
      "Processing datetime component of SNOTEL observation dataframe\n",
      "Loading all available processed ASO observations for the S_Sierras at 100M resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting ASO observations and Snotel observations for 20130403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 28946/120433 [00:48<02:38, 576.53it/s]"
     ]
    }
   ],
   "source": [
    "import Obs_to_DF\n",
    "region = \"S_Sierras\"\n",
    "output_res = 100\n",
    "\n",
    "#Connect nearest snotel observations with ASO data,\n",
    "finaldf = Obs_to_DF.Nearest_Snotel_2_obs(region, output_res, dropna = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "696c82d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>cen_lat</th>\n",
       "      <th>cen_lon</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Elevation_m</th>\n",
       "      <th>Slope_Deg</th>\n",
       "      <th>Aspect_Deg</th>\n",
       "      <th>swe</th>\n",
       "      <th>nearest_site_1</th>\n",
       "      <th>nearest_site_2</th>\n",
       "      <th>nearest_site_3</th>\n",
       "      <th>nearest_site_4</th>\n",
       "      <th>nearest_site_5</th>\n",
       "      <th>nearest_site_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11N_cell_-119.59073383567106_38.18624284828164</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>38.185854</td>\n",
       "      <td>-119.590255</td>\n",
       "      <td>POINT (-119.5902546710551 38.18585423359679)</td>\n",
       "      <td>3167.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.972643</td>\n",
       "      <td>44.52</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11N_cell_-119.58959364631137_38.186209698720205</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>38.185854</td>\n",
       "      <td>-119.589255</td>\n",
       "      <td>POINT (-119.58925467105512 38.18585423359679)</td>\n",
       "      <td>3168.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.536205</td>\n",
       "      <td>44.52</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11N_cell_-119.59309813700962_38.184509449472536</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>38.184854</td>\n",
       "      <td>-119.593255</td>\n",
       "      <td>POINT (-119.5932546710551 38.1848542335968)</td>\n",
       "      <td>3156.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>0.719424</td>\n",
       "      <td>44.52</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11N_cell_-119.59195797185825_38.18447632413384</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>38.184854</td>\n",
       "      <td>-119.592255</td>\n",
       "      <td>POINT (-119.59225467105512 38.1848542335968)</td>\n",
       "      <td>3158.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.618731</td>\n",
       "      <td>44.52</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11N_cell_-119.59081780857791_38.184443187748315</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>38.184854</td>\n",
       "      <td>-119.591255</td>\n",
       "      <td>POINT (-119.59125467105513 38.1848542335968)</td>\n",
       "      <td>3165.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.471944</td>\n",
       "      <td>44.52</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cell_id       Date    cen_lat  \\\n",
       "0   11N_cell_-119.59073383567106_38.18624284828164 2013-04-03  38.185854   \n",
       "1  11N_cell_-119.58959364631137_38.186209698720205 2013-04-03  38.185854   \n",
       "2  11N_cell_-119.59309813700962_38.184509449472536 2013-04-03  38.184854   \n",
       "3   11N_cell_-119.59195797185825_38.18447632413384 2013-04-03  38.184854   \n",
       "4  11N_cell_-119.59081780857791_38.184443187748315 2013-04-03  38.184854   \n",
       "\n",
       "      cen_lon                                       geometry  Elevation_m  \\\n",
       "0 -119.590255   POINT (-119.5902546710551 38.18585423359679)       3167.0   \n",
       "1 -119.589255  POINT (-119.58925467105512 38.18585423359679)       3168.0   \n",
       "2 -119.593255    POINT (-119.5932546710551 38.1848542335968)       3156.0   \n",
       "3 -119.592255   POINT (-119.59225467105512 38.1848542335968)       3158.0   \n",
       "4 -119.591255   POINT (-119.59125467105513 38.1848542335968)       3165.0   \n",
       "\n",
       "   Slope_Deg  Aspect_Deg       swe  nearest_site_1  nearest_site_2  \\\n",
       "0        0.0       180.0  0.972643           44.52            49.0   \n",
       "1        2.0        18.0  0.536205           44.52            49.0   \n",
       "2        5.0       342.0  0.719424           44.52            49.0   \n",
       "3        5.0        34.0  0.618731           44.52            49.0   \n",
       "4        8.0        32.0  0.471944           44.52            49.0   \n",
       "\n",
       "   nearest_site_3  nearest_site_4  nearest_site_5  nearest_site_6  \n",
       "0             0.0             0.1            18.9            18.8  \n",
       "1             0.0             0.1            18.9            18.8  \n",
       "2             0.0             0.1            18.9            18.8  \n",
       "3             0.0             0.1            18.9            18.8  \n",
       "4             0.0             0.1            18.9            18.8  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38f5171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c97bfa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d7de7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3ee8182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading goeospatial meta data for grids in S_Sierras\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>cen_lat</th>\n",
       "      <th>cen_lon</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Elevation_m</th>\n",
       "      <th>Slope_Deg</th>\n",
       "      <th>Aspect_Deg</th>\n",
       "      <th>swe</th>\n",
       "      <th>nearest site 1</th>\n",
       "      <th>nearest site 2</th>\n",
       "      <th>nearest site 3</th>\n",
       "      <th>nearest site 4</th>\n",
       "      <th>nearest site 5</th>\n",
       "      <th>nearest site 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11N_cell_-119.59073383567106_38.18624284828164</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>38.185854</td>\n",
       "      <td>-119.590255</td>\n",
       "      <td>POINT (-119.5902546710551 38.18585423359679)</td>\n",
       "      <td>3167.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.972643</td>\n",
       "      <td>44.52</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11N_cell_-119.58959364631137_38.186209698720205</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>38.185854</td>\n",
       "      <td>-119.589255</td>\n",
       "      <td>POINT (-119.58925467105512 38.18585423359679)</td>\n",
       "      <td>3168.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.536205</td>\n",
       "      <td>44.52</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11N_cell_-119.59309813700962_38.184509449472536</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>38.184854</td>\n",
       "      <td>-119.593255</td>\n",
       "      <td>POINT (-119.5932546710551 38.1848542335968)</td>\n",
       "      <td>3156.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>0.719424</td>\n",
       "      <td>44.52</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11N_cell_-119.59195797185825_38.18447632413384</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>38.184854</td>\n",
       "      <td>-119.592255</td>\n",
       "      <td>POINT (-119.59225467105512 38.1848542335968)</td>\n",
       "      <td>3158.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.618731</td>\n",
       "      <td>44.52</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11N_cell_-119.59081780857791_38.184443187748315</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>38.184854</td>\n",
       "      <td>-119.591255</td>\n",
       "      <td>POINT (-119.59125467105513 38.1848542335968)</td>\n",
       "      <td>3165.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.471944</td>\n",
       "      <td>44.52</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cell_id       Date    cen_lat  \\\n",
       "0   11N_cell_-119.59073383567106_38.18624284828164 2013-04-03  38.185854   \n",
       "1  11N_cell_-119.58959364631137_38.186209698720205 2013-04-03  38.185854   \n",
       "2  11N_cell_-119.59309813700962_38.184509449472536 2013-04-03  38.184854   \n",
       "3   11N_cell_-119.59195797185825_38.18447632413384 2013-04-03  38.184854   \n",
       "4  11N_cell_-119.59081780857791_38.184443187748315 2013-04-03  38.184854   \n",
       "\n",
       "      cen_lon                                       geometry  Elevation_m  \\\n",
       "0 -119.590255   POINT (-119.5902546710551 38.18585423359679)       3167.0   \n",
       "1 -119.589255  POINT (-119.58925467105512 38.18585423359679)       3168.0   \n",
       "2 -119.593255    POINT (-119.5932546710551 38.1848542335968)       3156.0   \n",
       "3 -119.592255   POINT (-119.59225467105512 38.1848542335968)       3158.0   \n",
       "4 -119.591255   POINT (-119.59125467105513 38.1848542335968)       3165.0   \n",
       "\n",
       "   Slope_Deg  Aspect_Deg       swe  nearest site 1  nearest site 2  \\\n",
       "0        0.0       180.0  0.972643           44.52            49.0   \n",
       "1        2.0        18.0  0.536205           44.52            49.0   \n",
       "2        5.0       342.0  0.719424           44.52            49.0   \n",
       "3        5.0        34.0  0.618731           44.52            49.0   \n",
       "4        8.0        32.0  0.471944           44.52            49.0   \n",
       "\n",
       "   nearest site 3  nearest site 4  nearest site 5  nearest site 6  \n",
       "0             0.0             0.1            18.9            18.8  \n",
       "1             0.0             0.1            18.9            18.8  \n",
       "2             0.0             0.1            18.9            18.8  \n",
       "3             0.0             0.1            18.9            18.8  \n",
       "4             0.0             0.1            18.9            18.8  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get Geospatial meta data\n",
    "print(f\"Loading goeospatial meta data for grids in {region}\")\n",
    "geodf_path = f\"{HOME}/SWEMLv2.0/data/TrainingDFs/{region}\"\n",
    "\n",
    "aso_gdf = pd.read_csv(f\"{geodf_path}/{region}_metadata.parquet\")\n",
    "aso_gdf\n",
    "\n",
    "df = pd.merge(finaldf, aso_gdf, on = 'cell_id', how = 'left')\n",
    "cols = [\n",
    "    'cell_id', 'Date',  'cen_lat', 'cen_lon', 'geometry', 'Elevation_m', 'Slope_Deg',\n",
    "       'Aspect_Deg', 'swe', 'nearest_site 1', 'nearest site 2', 'nearest site 3', 'nearest site 4', \n",
    "       'nearest site 5', 'nearest site 6'\n",
    "      ]\n",
    "df = df[cols]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ec78384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cell_id', 'Date', 'swe', 'nearest site 1', 'nearest site 4',\n",
       "       'nearest site 2', 'nearest site 6', 'nearest site 3', 'nearest site 5',\n",
       "       'cen_lon', 'cen_lat', 'geometry', 'Elevation_m', 'Slope_Deg',\n",
       "       'Aspect_Deg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7db66374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>swe</th>\n",
       "      <th>nearest site 1</th>\n",
       "      <th>nearest site 4</th>\n",
       "      <th>nearest site 2</th>\n",
       "      <th>nearest site 6</th>\n",
       "      <th>nearest site 3</th>\n",
       "      <th>nearest site 5</th>\n",
       "      <th>cen_lon</th>\n",
       "      <th>cen_lat</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Elevation_m</th>\n",
       "      <th>Slope_Deg</th>\n",
       "      <th>Aspect_Deg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11N_cell_-119.59073383567106_38.18624284828164</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>0.972643</td>\n",
       "      <td>44.52</td>\n",
       "      <td>0.1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>-119.590255</td>\n",
       "      <td>38.185854</td>\n",
       "      <td>POINT (-119.5902546710551 38.18585423359679)</td>\n",
       "      <td>3167.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11N_cell_-119.58959364631137_38.186209698720205</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>0.536205</td>\n",
       "      <td>44.52</td>\n",
       "      <td>0.1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>-119.589255</td>\n",
       "      <td>38.185854</td>\n",
       "      <td>POINT (-119.58925467105512 38.18585423359679)</td>\n",
       "      <td>3168.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11N_cell_-119.59309813700962_38.184509449472536</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>0.719424</td>\n",
       "      <td>44.52</td>\n",
       "      <td>0.1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>-119.593255</td>\n",
       "      <td>38.184854</td>\n",
       "      <td>POINT (-119.5932546710551 38.1848542335968)</td>\n",
       "      <td>3156.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11N_cell_-119.59195797185825_38.18447632413384</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>0.618731</td>\n",
       "      <td>44.52</td>\n",
       "      <td>0.1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>-119.592255</td>\n",
       "      <td>38.184854</td>\n",
       "      <td>POINT (-119.59225467105512 38.1848542335968)</td>\n",
       "      <td>3158.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11N_cell_-119.59081780857791_38.184443187748315</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>0.471944</td>\n",
       "      <td>44.52</td>\n",
       "      <td>0.1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>-119.591255</td>\n",
       "      <td>38.184854</td>\n",
       "      <td>POINT (-119.59125467105513 38.1848542335968)</td>\n",
       "      <td>3165.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cell_id       Date       swe  \\\n",
       "0   11N_cell_-119.59073383567106_38.18624284828164 2013-04-03  0.972643   \n",
       "1  11N_cell_-119.58959364631137_38.186209698720205 2013-04-03  0.536205   \n",
       "2  11N_cell_-119.59309813700962_38.184509449472536 2013-04-03  0.719424   \n",
       "3   11N_cell_-119.59195797185825_38.18447632413384 2013-04-03  0.618731   \n",
       "4  11N_cell_-119.59081780857791_38.184443187748315 2013-04-03  0.471944   \n",
       "\n",
       "   nearest site 1  nearest site 4  nearest site 2  nearest site 6  \\\n",
       "0           44.52             0.1            49.0            18.8   \n",
       "1           44.52             0.1            49.0            18.8   \n",
       "2           44.52             0.1            49.0            18.8   \n",
       "3           44.52             0.1            49.0            18.8   \n",
       "4           44.52             0.1            49.0            18.8   \n",
       "\n",
       "   nearest site 3  nearest site 5     cen_lon    cen_lat  \\\n",
       "0             0.0            18.9 -119.590255  38.185854   \n",
       "1             0.0            18.9 -119.589255  38.185854   \n",
       "2             0.0            18.9 -119.593255  38.184854   \n",
       "3             0.0            18.9 -119.592255  38.184854   \n",
       "4             0.0            18.9 -119.591255  38.184854   \n",
       "\n",
       "                                        geometry  Elevation_m  Slope_Deg  \\\n",
       "0   POINT (-119.5902546710551 38.18585423359679)       3167.0        0.0   \n",
       "1  POINT (-119.58925467105512 38.18585423359679)       3168.0        2.0   \n",
       "2    POINT (-119.5932546710551 38.1848542335968)       3156.0        5.0   \n",
       "3   POINT (-119.59225467105512 38.1848542335968)       3158.0        5.0   \n",
       "4   POINT (-119.59125467105513 38.1848542335968)       3165.0        8.0   \n",
       "\n",
       "   Aspect_Deg  \n",
       "0       180.0  \n",
       "1        18.0  \n",
       "2       342.0  \n",
       "3        34.0  \n",
       "4        32.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.merge(finaldf, aso_gdf, on = 'cell_id', how = 'left')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de858a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81392905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbcb6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc4c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with metadata\n",
    "req_cols = ['cell_id', 'lat', 'lon', 'BR_Coord_Long', 'BR_Coord_Lat', 'UR_Coord_Long', 'UR_Coord_Lat',\n",
    "            'UL_Coord_Long', 'UL_Coord_Lat', 'BL_Coord_Long', 'BL_Coord_Lat', 'geometry']\n",
    "Result = final_df.merge(metadata[req_cols], how='left', on='cell_id')\n",
    "\n",
    "# Column renaming and ordering\n",
    "Result.rename(columns={'swe': 'ASO_SWE_in'}, inplace=True)\n",
    "Result = Result[['cell_id', 'Date', 'ASO_SWE_in', 'lat', 'lon', 'nearest site 1', 'nearest site 2',\n",
    "                    'nearest site 3', 'nearest site 4', 'nearest site 5', 'nearest site 6',\n",
    "                    'BR_Coord_Long', 'BR_Coord_Lat', 'UR_Coord_Long', 'UR_Coord_Lat',\n",
    "                    'UL_Coord_Long', 'UL_Coord_Lat', 'BL_Coord_Long', 'BL_Coord_Lat']]\n",
    "\n",
    "# Save the merged data to a new file\n",
    "output_filename = f\"{HOME}/SWEML/data/NSMv2.0/data/TrainingDFs/Merged_aso_snotel_data.parquet\"\n",
    "Result.to_csv(output_filename, index=False)\n",
    "display(Result.head(10))\n",
    "print(\"Processed and saved data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6274b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'S_Sierras'\n",
    "ASO_meta_loc_DF = pd.read_csv(f\"{HOME}/SWEMLv2.0/data/TrainingDFs/{region}/ASO_meta.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c57e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect nearest snotel with ASO data, this should be last for now, need to add geophysical characteristics to the site first, then this...\n",
    "finaldf = GeoDF.Nearest_Snotel_2_obs(region, output_res, dropna = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cadb296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414fcbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b02171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c9ca2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b0d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ff590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662e5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277563f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d236591a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cb0f3a-7713-45d2-881f-574037b3a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A Simple implementation of parallel processing using concurrency it takes so long to execute,\n",
    "Explore terrain_daskconcurrency and terrain-processing_cluster python for more optimized implementations.\n",
    "\"\"\"\n",
    "\n",
    "def process_single_location(args):\n",
    "    lat, lon, regions, tiles = args\n",
    "    print(lat, lon, regions, tiles)\n",
    "\n",
    "    if (lat, lon) in elevation_cache:\n",
    "        elev, slop, asp = elevation_cache[(lat, lon)]\n",
    "        return elev, slop, asp\n",
    "\n",
    "    tile_id = 'Copernicus_DSM_COG_30_N' + str(math.floor(lon)) + '_00_W' + str(math.ceil(abs(lat))) + '_00_DEM'\n",
    "    index_id = regions.loc[tile_id]['sliceID']\n",
    "\n",
    "    signed_asset = planetary_computer.sign(tiles[index_id].assets[\"data\"])\n",
    "    #print(signed_asset)\n",
    "    elevation = rxr.open_rasterio(signed_asset.href)\n",
    "    \n",
    "    slope = elevation.copy()\n",
    "    aspect = elevation.copy()\n",
    "\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", elevation.rio.crs, always_xy=True)\n",
    "    xx, yy = transformer.transform(lon, lat)\n",
    "\n",
    "    tilearray = np.around(elevation.values[0]).astype(int)\n",
    "    #print(tilearray)\n",
    "    geo = (math.floor(float(lon)), 90, 0.0, math.ceil(float(lat)), 0.0, -90)\n",
    "\n",
    "    no_data_value = -9999\n",
    "    driver = gdal.GetDriverByName('MEM')\n",
    "    temp_ds = driver.Create('', tilearray.shape[1], tilearray.shape[0], 1, gdalconst.GDT_Float32)\n",
    "\n",
    "    temp_ds.GetRasterBand(1).WriteArray(tilearray)\n",
    "    temp_ds.GetRasterBand(1).SetNoDataValue(no_data_value)\n",
    "    temp_ds.SetProjection('EPSG:4326')\n",
    "    temp_ds.SetGeoTransform(geo)\n",
    "\n",
    "    tilearray_np = temp_ds.GetRasterBand(1).ReadAsArray()\n",
    "    slope_arr, aspect_arr = np.gradient(tilearray_np)\n",
    "    aspect_arr = np.rad2deg(np.arctan2(aspect_arr[0], aspect_arr[1]))\n",
    "    \n",
    "    slope.values[0] = slope_arr\n",
    "    aspect.values[0] = aspect_arr\n",
    "\n",
    "    elev = round(elevation.sel(x=xx, y=yy, method=\"nearest\").values[0])\n",
    "    slop = round(slope.sel(x=xx, y=yy, method=\"nearest\").values[0])\n",
    "    asp = round(aspect.sel(x=xx, y=yy, method=\"nearest\").values[0])\n",
    "\n",
    "    elevation_cache[(lat, lon)] = (elev, slop, asp)  \n",
    "    return elev, slop, asp\n",
    "\n",
    "def extract_terrain_data_threaded(metadata_df, bounding_box, max_workers=10):\n",
    "    global elevation_cache \n",
    "\n",
    "    elevation_cache = {} \n",
    "    min_x, min_y, max_x, max_y = *bounding_box[0], *bounding_box[1]\n",
    "    \n",
    "    client = Client.open(\n",
    "            \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "            ignore_conformance=True,\n",
    "        )\n",
    "\n",
    "    search = client.search(\n",
    "                    collections=[\"cop-dem-glo-90\"],\n",
    "                    intersects = {\n",
    "                            \"type\": \"Polygon\",\n",
    "                            \"coordinates\": [[\n",
    "                            [min_x, min_y],\n",
    "                            [max_x, min_y],\n",
    "                            [max_x, max_y],\n",
    "                            [min_x, max_y],\n",
    "                            [min_x, min_y]  \n",
    "                        ]]})\n",
    "\n",
    "    tiles = list(search.items())\n",
    "\n",
    "    regions = []\n",
    "\n",
    "    print(\"Retrieving Copernicus 90m DEM tiles\")\n",
    "    for i in tqdm(range(0, len(tiles))):\n",
    "        row = [i, tiles[i].id]\n",
    "        regions.append(row)\n",
    "    regions = pd.DataFrame(columns = ['sliceID', 'tileID'], data = regions)\n",
    "    regions = regions.set_index(regions['tileID'])\n",
    "    del regions['tileID']\n",
    "\n",
    "    print(\"Interpolating Grid Cell Spatial Features\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(process_single_location, (metadata_df.iloc[i]['cen_lat'], metadata_df.iloc[i]['cen_lon'], regions, tiles))\n",
    "                   for i in tqdm(range(len(metadata_df)))]\n",
    "        \n",
    "        results = []\n",
    "        for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "            results.append(future.result())\n",
    "    \n",
    "    metadata_df['Elevation_m'], metadata_df['Slope_Deg'], metadata_df['Aspect_L'] = zip(*results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f281ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(r\"/home/vgindi/Provided_Data/Merged_aso_nearest_sites1.csv\")\n",
    "metadata_df= metadata_df.head(20)\n",
    "bounding_box = ((-120.3763448720203, 36.29256774541929), (-118.292253412863, 38.994985247736324))    \n",
    "    \n",
    "extract_terrain_data_threaded(metadata_df, bounding_box)\n",
    "\n",
    "# Display the results\n",
    "metadata_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f6975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050495d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b59f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aee4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e093705e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f714b0f0-1c38-4ba3-8aed-1ca6b97c2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code block crops the global coverage VIIRS data to south sierras subregion. \n",
    "\"\"\"\n",
    "\n",
    "def crop_sierras(input_file_path, output_file_path, shapes):\n",
    "    with rasterio.open(input_file_path) as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "        out_meta = src.out_meta\n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "                         \"height\": out_image.shape[1],\n",
    "                         \"width\": out_image.shape[2],\n",
    "                         \"transform\": out_transform})\n",
    "                         \n",
    "        with rasterio.open(output_file_path, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "\n",
    "def download_viirs_sca(input_dir, output_dir, shapefile_path):\n",
    "    \n",
    "    # Load shapes from the shapefile\n",
    "    with fiona.open(shapefile_path, 'r') as shapefile:\n",
    "        shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "    \n",
    "    # Iterate through each year directory in the input directory\n",
    "    for year_folder in os.listdir(input_dir):\n",
    "        year_folder_path = os.path.join(input_dir, year_folder)\n",
    "        if os.path.isdir(year_folder_path):\n",
    "            # Extract year from the folder name (assuming folder names like 'WY2013')\n",
    "            year = re.search(r'\\d{4}', year_folder).group()\n",
    "            output_year_folder = os.path.join(output_dir, year)\n",
    "            os.makedirs(output_year_folder, exist_ok=True)\n",
    "        \n",
    "            for file_name in os.listdir(year_folder_path):        \n",
    "                if file_name.endswith('.tif'):   \n",
    "                    parts = file_name.split('_')\n",
    "                    output_file_name = '_'.join(parts[:3]) + '.tif'\n",
    "                    output_file_path = os.path.join(output_year_folder, output_file_name)\n",
    "                    input_file_path = os.path.join(year_folder_path, file_name)\n",
    "                    crop_sierras(input_file_path, output_file_path, shapes)\n",
    "                    print(f\"Processed and saved {output_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    input_directory = r\"/home/vgindi/VIIRS_Data\"\n",
    "    output_directory = r\"/home/vgindi/VIIRS_Sierras\"\n",
    "    shapefile_path = r\"/home/vgindi/Provided_Data/low_sierras_points.shp\"\n",
    "    download_viirs_sca(input_directory, output_directory, shapefile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ab2744-b080-48c8-bb77-f4b9c14ca774",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code cell transforms the raw VIIRS tiff files to 100m resolution and saves each file in .csv format\n",
    "\"\"\"\n",
    "def processing_VIIRS(input_file, output_res):\n",
    "    try:\n",
    "        # Define the output file path for TIFFs using the original file name\n",
    "        output_folder_tiff = os.path.join(\"/home/vgindi/Processed_VIIRS\", os.path.basename(os.path.dirname(input_file)))\n",
    "        os.makedirs(output_folder_tiff, exist_ok=True)\n",
    "        output_file = os.path.join(output_folder_tiff, os.path.basename(input_file))\n",
    "\n",
    "        # Reproject and resample\n",
    "        ds = gdal.Open(input_file)\n",
    "        if ds is None:\n",
    "            print(f\"Failed to open '{input_file}'. Make sure the file is a valid GeoTIFF file.\")\n",
    "            return None\n",
    "        \n",
    "        gdal.Warp(output_file, ds, dstSRS=\"EPSG:4326\", xRes=output_res, yRes=-output_res, resampleAlg=\"bilinear\")\n",
    "\n",
    "        # Read the processed TIFF file using rasterio\n",
    "        rds = rxr.open_rasterio(output_file)\n",
    "        rds = rds.squeeze().drop(\"spatial_ref\").drop(\"band\")\n",
    "        rds.name = \"data\"\n",
    "        df = rds.to_dataframe().reset_index()\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_and_convert_viirs(input_dir, output_res):\n",
    "    # Iterate over subdirectories in the input directory\n",
    "    for year in os.listdir(input_dir):\n",
    "        year_dir = os.path.join(input_dir, year)\n",
    "        \n",
    "        if os.path.isdir(year_dir):\n",
    "            for file_name in os.listdir(year_dir):\n",
    "                if file_name.endswith('.tif'):\n",
    "                    input_file_path = os.path.join(year_dir, file_name)\n",
    "                    df = processing_VIIRS(input_file_path, output_res)\n",
    "                    \n",
    "                    if df is not None:\n",
    "                        csv_folder = os.path.join(\"/home/vgindi/Processed_VIIRS\", \"VIIRS_csv\")\n",
    "                        os.makedirs(csv_folder, exist_ok=True)\n",
    "                        csv_file_path = os.path.join(csv_folder, file_name.replace('.tif', '.csv'))\n",
    " \n",
    "                        df.to_csv(csv_file_path, index=False)\n",
    "                        print(f\"Processed and saved {csv_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_directory = \"/home/vgindi/VIIRS_Sierras\"\n",
    "    output_res = 100  # Desired resolution in meters\n",
    "    process_and_convert_viirs(input_directory, output_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e2831c-817d-40b5-a2e0-d9ebff8a5672",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code cell fetches the cell id using grid_cells_meta_idx metadata for each lat/lon pair for VIIRS csv file\n",
    "\"\"\"\n",
    "def create_polygon(self, row):\n",
    "    return Polygon([(row['BL_Coord_Long'], row['BL_Coord_Lat']),\n",
    "                    (row['BR_Coord_Long'], row['BR_Coord_Lat']),\n",
    "                    (row['UR_Coord_Long'], row['UR_Coord_Lat']),\n",
    "                    (row['UL_Coord_Long'], row['UL_Coord_Lat'])])\n",
    "    \n",
    "def process_folder(self, input_folder, metadata_path, output_folder):\n",
    "    # Import the metadata into a pandas DataFrame\n",
    "    pred_obs_metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "    # Assuming create_polygon is defined elsewhere, we add a column with polygon geometries\n",
    "    pred_obs_metadata_df = pred_obs_metadata_df.drop(columns=['Unnamed: 0'], axis=1)\n",
    "    pred_obs_metadata_df['geometry'] = pred_obs_metadata_df.apply(self.create_polygon, axis=1)\n",
    "\n",
    "    # Convert the DataFrame to a GeoDataFrame\n",
    "    metadata = gpd.GeoDataFrame(pred_obs_metadata_df, geometry='geometry')\n",
    "\n",
    "    # Drop coordinates columns\n",
    "    metadata = metadata.drop(columns=['BL_Coord_Long', 'BL_Coord_Lat', \n",
    "                                         'BR_Coord_Long', 'BR_Coord_Lat', \n",
    "                                         'UR_Coord_Long', 'UR_Coord_Lat', \n",
    "                                         'UL_Coord_Long', 'UL_Coord_Lat'], axis=1)\n",
    "\n",
    "    # List all CSV files in the input folder\n",
    "    csv_files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        input_path = os.path.join(input_folder, csv_file)\n",
    "        output_path = os.path.join(output_folder, csv_file)\n",
    "\n",
    "        # Check if the output file already exists\n",
    "        if os.path.exists(output_path):\n",
    "            print(f\"CSV file {csv_file} already exists in the output folder.\")\n",
    "            continue\n",
    "\n",
    "        # Process each CSV file\n",
    "        viirs_sca_df = pd.read_csv(input_path)\n",
    "\n",
    "        # Convert the \"aso_swe_df\" into a GeoDataFrame with point geometries\n",
    "        geometry = [Point(xy) for xy in zip(viirs_sca_df['x'], viirs_sca_df['y'])]\n",
    "        viirs_sca_geo = gpd.GeoDataFrame(viirs_sca_df, geometry=geometry)\n",
    "        result = gpd.sjoin(viirs_sca_geo, metadata, how='left', predicate='within', op = 'intersects')\n",
    "\n",
    "        # Select specific columns for the final DataFrame\n",
    "        Final_df = result[['y', 'x', 'data', 'cell_id']]\n",
    "        Final_df.rename(columns={'data': 'VIIRS_SCA'}, inplace=True)\n",
    "\n",
    "        # Drop rows where 'cell_id' is NaN\n",
    "        if Final_df['cell_id'].isnull().values.any():\n",
    "            Final_df = Final_df.dropna(subset=['cell_id'])\n",
    "\n",
    "        # Save the processed DataFrame to a CSV file\n",
    "        Final_df.to_csv(output_path, index=False)\n",
    "        print(f\"Processed {csv_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = r\"\"\n",
    "    metadata_path = r\"\"\n",
    "    output_folder = r\"\"\n",
    "    process_folder(input_folder, metadata_path, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SWEML_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
